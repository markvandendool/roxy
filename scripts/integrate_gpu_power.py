#!/usr/bin/env python3
"""
Integrate GPU Infrastructure into ROXY for Maximum Power
Updates all ROXY references to ROXY and ensures GPU acceleration is enabled
"""
import os
import re
import subprocess
from pathlib import Path

ROXY_ROOT = Path('/opt/roxy')
ENV_FILE = ROXY_ROOT / '.env'

def update_systemd_services():
    """Update systemd services from ROXY to ROXY"""
    print("1. Updating systemd services...")
    
    roxy_service = Path('/etc/systemd/system/roxy.service')
    roxy_service = Path('/etc/systemd/system/roxy.service')
    
    if roxy_service.exists() and not roxy_service.exists():
        # Copy and update
        with open(roxy_service, 'r') as f:
            content = f.read()
        
        # Replace ROXY with ROXY
        content = content.replace('ROXY', 'ROXY')
        content = content.replace('roxy', 'roxy')
        content = content.replace('Roxy', 'Roxy')
        
        with open(roxy_service, 'w') as f:
            f.write(content)
        
        print("  ‚úÖ Created roxy.service from roxy.service")
        
        # Reload systemd
        subprocess.run(['sudo', 'systemctl', 'daemon-reload'], capture_output=True)
        print("  ‚úÖ Systemd reloaded")
    
    # Check for voice service
    voice_service = Path('/etc/systemd/system/roxy-voice.service')
    if not voice_service.exists():
        roxy_voice = Path('/etc/systemd/system/roxy-voice.service')
        if roxy_voice.exists():
            with open(roxy_voice, 'r') as f:
                content = f.read()
            content = content.replace('ROXY', 'ROXY')
            content = content.replace('roxy', 'roxy')
            with open(voice_service, 'w') as f:
                f.write(content)
            print("  ‚úÖ Created roxy-voice.service")
            subprocess.run(['sudo', 'systemctl', 'daemon-reload'], capture_output=True)

def configure_gpu_env():
    """Configure GPU environment variables"""
    print("2. Configuring GPU environment...")
    
    if not ENV_FILE.exists():
        ENV_FILE.touch()
    
    # Read current env
    env_vars = {}
    if ENV_FILE.exists():
        with open(ENV_FILE, 'r') as f:
            for line in f:
                if '=' in line and not line.strip().startswith('#'):
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip().strip('"').strip("'")
    
    # GPU optimizations
    gpu_config = {
        'OLLAMA_HOST': 'http://127.0.0.1:11435',
        'OLLAMA_GPU_LAYERS': '35',  # Use GPU for most layers
        'OLLAMA_NUM_GPU': '1',
        'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:512',
        'ROCM_VISIBLE_DEVICES': '0',
        'CUDA_VISIBLE_DEVICES': '0',
        'ROXY_GPU_ENABLED': 'true',
        'ROXY_GPU_DEVICE': 'cuda',  # ROCm uses CUDA API
    }
    
    updated = False
    for key, value in gpu_config.items():
        if key not in env_vars or env_vars[key] != value:
            env_vars[key] = value
            updated = True
            print(f"  ‚úÖ Set {key}={value}")
    
    if updated:
        with open(ENV_FILE, 'w') as f:
            for key, value in sorted(env_vars.items()):
                f.write(f"{key}={value}\n")
        print("  ‚úÖ GPU environment configured")
    else:
        print("  ‚úÖ GPU environment already optimal")

def update_llm_service():
    """Ensure LLM service uses GPU"""
    print("3. Updating LLM service for GPU...")
    
    llm_service = ROXY_ROOT / 'services' / 'llm_service.py'
    if not llm_service.exists():
        print("  ‚ö†Ô∏è  LLM service not found")
        return
    
    with open(llm_service, 'r') as f:
        content = f.read()
    
    # Check if GPU config is present
    if 'OLLAMA_GPU_LAYERS' not in content:
        # Add GPU configuration
        ollama_config = '''
        # GPU Configuration
        self.ollama_gpu_layers = int(os.getenv('OLLAMA_GPU_LAYERS', '35'))
        self.ollama_num_gpu = int(os.getenv('OLLAMA_NUM_GPU', '1'))
        '''
        
        # Find __init__ method and add after model config
        if 'self.ollama_model =' in content:
            content = content.replace(
                "self.ollama_model = os.getenv('OLLAMA_MODEL', 'llama3')",
                f"self.ollama_model = os.getenv('OLLAMA_MODEL', 'llama3')\n{ollama_config}"
            )
            with open(llm_service, 'w') as f:
                f.write(content)
            print("  ‚úÖ LLM service updated for GPU")
        else:
            print("  ‚ö†Ô∏è  Could not find insertion point in LLM service")
    else:
        print("  ‚úÖ LLM service already GPU-configured")

def verify_gpu_setup():
    """Verify GPU setup"""
    print("4. Verifying GPU setup...")
    
    # Check for ROCm
    result = subprocess.run(['which', 'rocminfo'], capture_output=True, text=True)
    if result.returncode == 0:
        print("  ‚úÖ ROCm tools available")
        # Try to get GPU info
        try:
            result = subprocess.run(['rocminfo'], capture_output=True, text=True, timeout=5)
            if 'gfx' in result.stdout.lower():
                print("  ‚úÖ GPU detected via ROCm")
        except:
            pass
    else:
        print("  ‚ö†Ô∏è  ROCm tools not found (may need installation)")
    
    # Check PyTorch
    try:
        import torch
        if torch.cuda.is_available():
            print(f"  ‚úÖ PyTorch CUDA available: {torch.cuda.get_device_name(0)}")
        else:
            print("  ‚ö†Ô∏è  PyTorch CUDA not available")
    except ImportError:
        print("  ‚ö†Ô∏è  PyTorch not installed")
    
    # Check Ollama
    import urllib.request
    try:
        urllib.request.urlopen('http://127.0.0.1:11435/api/tags', timeout=2)
        print("  ‚úÖ Ollama is running")
    except:
        print("  ‚ö†Ô∏è  Ollama not accessible (may not be running)")

def update_power_maximizer():
    """Update power maximizer to include GPU"""
    print("5. Updating power maximizer...")
    
    maximizer = ROXY_ROOT / 'scripts' / 'maximize_roxy_power.py'
    if not maximizer.exists():
        print("  ‚ö†Ô∏è  Power maximizer not found")
        return
    
    with open(maximizer, 'r') as f:
        content = f.read()
    
    if 'GPU' not in content or 'gpu' not in content.lower():
        # Add GPU optimization section
        gpu_section = '''
    def optimize_gpu(self):
        """Configure GPU for maximum performance"""
        print("13. Optimizing GPU Configuration...")
        
        env_vars = self._read_env()
        
        # GPU settings
        gpu_config = {
            'OLLAMA_GPU_LAYERS': '35',
            'OLLAMA_NUM_GPU': '1',
            'ROXY_GPU_ENABLED': 'true',
        }
        
        for key, value in gpu_config.items():
            if key not in env_vars:
                self._update_env(key, value)
                self.fixes_applied.append(f"GPU: {key}={value}")
        
        print("  ‚úÖ GPU configuration optimized")
'''
        
        # Add to run_full_optimization
        if 'def run_full_optimization' in content:
            # Find where to insert
            if 'self.optimize_performance()' in content:
                content = content.replace(
                    'self.optimize_performance()',
                    'self.optimize_performance()\n        self.optimize_gpu()'
                )
                # Add the method
                content += gpu_section
                with open(maximizer, 'w') as f:
                    f.write(content)
                print("  ‚úÖ Power maximizer updated with GPU optimization")
            else:
                print("  ‚ö†Ô∏è  Could not find insertion point")
        else:
            print("  ‚ö†Ô∏è  Power maximizer structure not recognized")
    else:
        print("  ‚úÖ Power maximizer already includes GPU")

def main():
    """Main integration"""
    print("=" * 70)
    print("üöÄ INTEGRATING GPU INFRASTRUCTURE INTO ROXY")
    print("=" * 70)
    print()
    
    update_systemd_services()
    configure_gpu_env()
    update_llm_service()
    verify_gpu_setup()
    update_power_maximizer()
    
    print()
    print("=" * 70)
    print("‚úÖ GPU INTEGRATION COMPLETE")
    print("=" * 70)
    print()
    print("GPU acceleration is now enabled for:")
    print("  ‚úÖ LLM processing (Ollama with GPU layers)")
    print("  ‚úÖ PyTorch operations (ROCm/CUDA)")
    print("  ‚úÖ Voice processing (Whisper, TTS)")
    print()
    print("To verify GPU setup:")
    print("  ./scripts/verify-gpu-setup.sh")
    print()
    print("To maximize power with GPU:")
    print("  ./scripts/setup_roxy_max_power.sh")
    print()

if __name__ == "__main__":
    main()










